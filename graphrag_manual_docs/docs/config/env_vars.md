# Default Configuration Mode (using Env Vars)

# Miscellaneous Settings

### Text-Embeddings Customization

### Input Data

### Base LLM Settings

### Text Generation Settings

### Text Embedding Settings

### Input Settings

### Data Mapping Settings

### Data Chunking

### Prompting Overrides

### Storage

### Cache

### Reporting

### Node2Vec Parameters

### Data Snapshotting

#### Embedded Fields

#### Plaintext Input Data (GRAPHRAG_INPUT_FILE_TYPE=text)

#### CSV Input Data (GRAPHRAG_INPUT_FILE_TYPE=csv)

As of version 1.3, GraphRAG no longer supports a full complement of pre-built environment variables. Instead, we support variable replacement within the settings.yml file so you can specify any environment variables you like.

The only standard environment variable we expect, and include in the default settings.yml, is GRAPHRAG_API_KEY. If you are already using a number of the previous GRAPHRAG_* environment variables, you can insert them with template syntax into settings.yml and they will be adopted.

The environment variables below are documented as an aid for migration, but they WILL NOT be read unless you use template syntax in your settings.yml.

By default, the GraphRAG indexer will only export embeddings required for our query methods. However, the model has embeddings defined for all plaintext fields, and these can be generated by setting the GRAPHRAG_EMBEDDING_TARGET environment variable to all.

Our pipeline can ingest .csv or .txt data from an input folder. These files can be nested within subfolders. To configure how input data is handled, what fields are mapped over, and how timestamps are parsed, look for configuration values starting with GRAPHRAG_INPUT_ below. In general, CSV-based data provides the most customizability. Each CSV should at least contain a text field (which can be mapped with environment variables), but it's helpful if they also have title, timestamp, and source fields. Additional fields can be included as well, which will land as extra fields on the Document table.

These are the primary settings for configuring LLM connectivity.

These settings control the text generation model used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.

These settings control the text embedding model used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.

These settings control the data input used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.

This section controls the storage mechanism used by the pipeline used for exporting output tables.

This section controls the cache mechanism used by the pipeline. This is used to cache LLM invocation results.

This section controls the reporting mechanism used by the pipeline, for common events and error messages. The default is to write reports to a file in the output directory. However, you can also choose to write reports to the console or to an Azure Blob Storage container.

- text_unit.text
- document.text
- entity.title
- entity.description
- relationship.description
- community.title
- community.summary
- community.full_content

[settings.yml file](https://microsoft.github.io/graphrag/../yaml/)

[(Azure limit is 16)](https://learn.microsoft.com/en-us/azure/ai-ce)

[(Azure limit is 8191)](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)

